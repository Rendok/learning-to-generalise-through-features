{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_kuka_multi_blocks.envs.kuka_multi_blocks_gym_env as e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = e.KukaMultiBlocksEnv(renders=True, numObjects=3, removeHeightHack=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "H = 1000\n",
    "obs_R = np.zeros(H)\n",
    "for k in range(H):\n",
    "    obs, rew, done, info = env.step([0,0,-1,0])#env.action_space.sample())\n",
    "    obs_R[k] = rew\n",
    "    if done: \n",
    "        # Note that behaviour of environments is not specified when one tries\n",
    "        # to step() on terminal states.\n",
    "        break \n",
    "    \n",
    "print('Reward: {}'.format(np.sum(obs_R)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.tune.logger import pretty_print\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.agents import ddpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(renders=False):\n",
    "    import gym\n",
    "    import gym_kuka_multi_blocks.envs.kuka_multi_blocks_gym_env as e\n",
    "    env = e.KukaMultiBlocksEnv(renders=renders,\n",
    "                               numObjects=3,\n",
    "                               removeHeightHack=True,\n",
    "                               isDiscrete=False)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPDG train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "config = ddpg.DEFAULT_CONFIG.copy()\n",
    "config[\"num_workers\"] = 4\n",
    "config[\"horizon\"] = 1000\n",
    "\n",
    "ray.init()\n",
    "\n",
    "agent = ddpg.DDPGAgent(config=config, env=\"my_env\")\n",
    "#agent.restore(\"/Users/dgrebenyuk/ray_results/2018-09-30_15-37-54bt93cdbw/checkpoint-842\")\n",
    "\n",
    "for i in range(1001):\n",
    "    # Perform one iteration of training the policy with PPO\n",
    "    result = agent.train()\n",
    "    print(pretty_print(result))\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        checkpoint = agent.save()\n",
    "        print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPDG test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/raylogs/.\n",
      "Waiting for redis server at 127.0.0.1:59683 to respond...\n",
      "Waiting for redis server at 127.0.0.1:54057 to respond...\n",
      "Starting local scheduler with the following resources: {'CPU': 4, 'GPU': 0}.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui23422.ipynb?token=8a61dc35207e9ba6c65d8d2704efd0f506dbb7dbe9adc11c\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=/Users/dgrebenyuk/Research/rl-task-planning/gym_kuka_multi_blocks/envs\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Created LogSyncer for /Users/dgrebenyuk/ray_results/2018-10-01_14-17-16xp46ragb -> None\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.55752967232337\n"
     ]
    }
   ],
   "source": [
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "config = ddpg.DEFAULT_CONFIG.copy()\n",
    "config[\"num_workers\"] = 4 # <--- change here\n",
    "config[\"horizon\"] = 1000\n",
    "\n",
    "ray.init()\n",
    "\n",
    "env = env_creator(renders=True)\n",
    "\n",
    "agent = ddpg.DDPGAgent(config=config, env=\"my_env\")\n",
    "agent.restore(\"./trained_policies/KukaMultiBlocks-v0-DDPG/2018-09-30_15-37-54bt93cdbw/checkpoint-842\")\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "reward = 0\n",
    "for _ in range(1000):\n",
    "    action_ = agent.compute_action(obs)\n",
    "    obs, rew, done, _ = env.step(action_)\n",
    "    reward += rew\n",
    "print(reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
