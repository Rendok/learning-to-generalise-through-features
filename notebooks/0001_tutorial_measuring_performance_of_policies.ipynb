{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Evaluating Policies & First Contact with State of the Art Continuous RL methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a hands-on tutorial to get familiar with the following topics:\n",
    "\n",
    " - OpenAI ```gym``` 2D \"videogame\" environments\n",
    " - State-of-the-art methods for RL over continuous control spaces\n",
    " - Measuring the performance of a given policy and reporting it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will rely heavily on four scientific Python computing frameworks:\n",
    "\n",
    " - Numpy & Scipy - we will use for high performance algebraic computation and statistical analysis\n",
    " - Pandas - very useful framework to analyze and manage complex datasets\n",
    " - Matplotlib - essential for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dateutil 2.5.0 is the minimum required version",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-51e788afe6f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# numpy compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdateutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2.5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dateutil 2.5.0 is the minimum required version'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdateutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_date_parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0mparse_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_date_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dateutil 2.5.0 is the minimum required version"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bipedal Walker\n",
    "\n",
    "Bipedal Walker is a straightforward task that can be decomposed into two subtasks. One is to keep the robot upright, as it lacks the means to pull itself back on its feet. The second is to move as fast as possible towards the right, as reward grows linearly with the distance from the origin. The first subtask needs to be achieved indifinetly and concurrently with the second one. \n",
    "\n",
    "Besides the challenge posed by the robot dynamics, 4(?) degrees of freedom, plus modeling of inertia, the ground is uneven. These \"bumps\" along the way complicate keeping balance while moving fast, as if the robot goes too fast it can be impossible to stabilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BipedalWalker-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 1000\n",
    "trials_per_checkpoint = 10\n",
    "checkpoints = []\n",
    "random_observed_R = []\n",
    "\n",
    "for trial in range(10, num_trials+1, trials_per_checkpoint):\n",
    "    R = 0\n",
    "    env.reset()\n",
    "    for t in range(100):\n",
    "        # the following call implements a random policy that picks actions from a uniform distribution\n",
    "        u_t = env.action_space.sample()\n",
    "        next, r, done, info = env.step(u_t)\n",
    "        R += r\n",
    "        # uncomment if capable of rendering\n",
    "        #env.render()\n",
    "        if done: break\n",
    "    checkpoints.append(trial)\n",
    "    random_observed_R.append(R)\n",
    "# uncomment if capable of rendering\n",
    "#env.close()\n",
    "checkpoints = np.array(checkpoints)\n",
    "random_observed_R = np.array(random_observed_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 1000\n",
    "trials_per_checkpoint = 10\n",
    "zero_observed_R = []\n",
    "\n",
    "for trial in range(10, num_trials+1, trials_per_checkpoint):\n",
    "    R = 0\n",
    "    env.reset()\n",
    "    for t in range(100):\n",
    "        # the following call implements a random policy that picks actions from a uniform distribution\n",
    "        u_t = np.zeros(env.action_space.shape)\n",
    "        next, r, done, info = env.step(u_t)\n",
    "        R += r\n",
    "        # uncomment if capable of rendering\n",
    "        #env.render()\n",
    "        if done: break\n",
    "    zero_observed_R.append(R)\n",
    "# uncomment if capable of rendering\n",
    "#env.close()\n",
    "\n",
    "zero_observed_R = np.array(zero_observed_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Policies Robustly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [ '#2D328F', '#F15C19',\"#81b13c\",\"#ca49ac\"]\n",
    "          \n",
    "label_fontsize = 18\n",
    "tick_fontsize = 14\n",
    "linewidth = 3\n",
    "markersize = 5\n",
    "\n",
    "median_zero = np.median(zero_observed_R)\n",
    "plt.plot([checkpoints[0],checkpoints[-1]], [median_zero, median_zero], color='#0000FF', linewidth=linewidth,\\\n",
    "             linestyle='--',label='Zero Control')\n",
    "median_random = np.median(random_observed_R)\n",
    "plt.plot([checkpoints[0],checkpoints[-1]], [median_random, median_random], color='#0000F3', linewidth=linewidth,\\\n",
    "             linestyle=':', label='Random Control')\n",
    "\n",
    "plt.axis([0,1000,-500,500])\n",
    "\n",
    "plt.xlabel('rollouts',fontsize=label_fontsize)\n",
    "plt.ylabel('R',fontsize=label_fontsize)\n",
    "plt.legend(fontsize=18, bbox_to_anchor=(1.0, 1.0))\n",
    "plt.xticks(fontsize=tick_fontsize)\n",
    "plt.yticks(fontsize=tick_fontsize)\n",
    "plt.grid(True)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(9, 6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State of the Art RL over Continuous Control Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ python -m ars --env_name gym:BipedalWalker-v2 --n_directions 240 --deltas_used 240 --step_size 0.02 \\ \n",
    "--delta_std 0.0075 --n_workers 6 --n_iter 1000 --address 10.100.228.201:6379\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ python3 -m ars.run_policy data/lin_policy_plus.npz BipedalWalker-v2 --render --num_rollouts 20\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pre-trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_render = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading and building expert policy')\n",
    "lin_policy = np.load(\"trained_policies/BipedalWalker-v1/e_545/lin_policy_plus.npz\")\n",
    "lin_policy = list(lin_policy.items())[0][1]\n",
    "\n",
    "M = lin_policy[0]\n",
    "# mean and std of state vectors estimated online by ARS.\n",
    "mean = lin_policy[1]\n",
    "std = lin_policy[2]\n",
    "\n",
    "env = gym.make('BipedalWalker-v2')\n",
    "\n",
    "returns = []\n",
    "observations = []\n",
    "actions = []\n",
    "for i in range(num_trials):\n",
    "    #print('iter', i)\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    totalr = 0.\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        action = np.dot(M, (obs - mean)/std)\n",
    "        observations.append(obs)\n",
    "        actions.append(action)\n",
    "\n",
    "\n",
    "        obs, r, done, _ = env.step(action)\n",
    "        totalr += r\n",
    "        steps += 1\n",
    "        if do_render:\n",
    "            env.render()\n",
    "        #if steps % 100 == 0: print(\"%i/%i\"%(steps, env.spec.timestep_limit))\n",
    "        if steps >= env.spec.timestep_limit:\n",
    "            break\n",
    "    returns.append(totalr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [ '#2D328F', '#F15C19',\"#81b13c\",\"#ca49ac\"]\n",
    "          \n",
    "label_fontsize = 18\n",
    "tick_fontsize = 14\n",
    "linewidth = 3\n",
    "markersize = 5\n",
    "\n",
    "median_zero = np.median(zero_observed_R)\n",
    "plt.plot([checkpoints[0],checkpoints[-1]], [median_zero, median_zero], color='#0000FF', linewidth=linewidth,\\\n",
    "             linestyle='--',label='Zero Control')\n",
    "median_random = np.median(random_observed_R)\n",
    "plt.plot([checkpoints[0],checkpoints[-1]], [median_random, median_random], color='#0000F3', linewidth=linewidth,\\\n",
    "             linestyle=':', label='Random Control')\n",
    "\n",
    "plt.plot(checkpoints, np.ones(checkpoints.shape)*np.median(returns, axis=0), \\\n",
    "         '--', color=colors[2], linewidth=linewidth, markersize=markersize,label='ARS, n=545')\n",
    "plt.fill_between(checkpoints, np.ones(checkpoints.shape)*np.min(returns, axis=0), \\\n",
    "                 np.ones(checkpoints.shape)*np.max(returns, axis=0), alpha=0.25)\n",
    "\n",
    "\n",
    "#plt.plot(tot_samples,np.median(J_finite_rs,axis=0),'s-',color=colors[1],linewidth=linewidth,\n",
    "#         markersize=markersize,label='random search')\n",
    "#plt.fill_between(tot_samples, np.amin(J_finite_rs,axis=0), np.amax(J_finite_rs,axis=0), alpha=0.25)\n",
    "\n",
    "#plt.plot(tot_samples,np.median(J_finite_nom,axis=0),'*-',color=colors[2],linewidth=linewidth,\n",
    "#         markersize=markersize,label='nominal')\n",
    "#plt.fill_between(tot_samples, np.amin(J_finite_nom,axis=0), np.amax(J_finite_nom,axis=0), alpha=0.25)\n",
    "\n",
    "#plt.plot([tot_samples[0],tot_samples[-1]],[baseline, baseline],color='#000000',linewidth=linewidth,\n",
    "#             linestyle='--',label='zero control')\n",
    "#plt.plot([tot_samples[0],tot_samples[-1]],[J_finite_opt, J_finite_opt],color='#000000',linewidth=linewidth,\n",
    "#             linestyle=':',label='optimal')\n",
    "\n",
    "plt.axis([0,1000,-500,500])\n",
    "\n",
    "plt.xlabel('rollouts',fontsize=label_fontsize)\n",
    "plt.ylabel('R',fontsize=label_fontsize)\n",
    "plt.legend(fontsize=8, bbox_to_anchor=(1.0, 1.0))\n",
    "plt.xticks(fontsize=tick_fontsize)\n",
    "plt.yticks(fontsize=tick_fontsize)\n",
    "plt.grid(True)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(9, 6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We never stop learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
